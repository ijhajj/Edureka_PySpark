{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SpamDetection Notebook\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = spark.read.option(\"delimiter\",\"\\t\").csv(\"/user/edureka_524533/Datasets/SMSSpamCollection\").toDF(\"spam\",\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract word\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer().setInputCol(\"message\").setOutputCol(\"words\")\n",
    "transformed = tokenizer.transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + [\"-\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to binary label\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "indexer = StringIndexer().setInputCol(\"spam\").setOutputCol(\"label\").fit(featured)\n",
    "indexed = indexer.transform(featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to train and test\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "training, test = indexed.randomSplit([0.7, 0.3], seed = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "lrModel = lr.fit(training)\n",
    "predictions = lrModel.transform(test)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(2)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "tokenizer = Tokenizer().setInputCol(\"message\").setOutputCol(\"words\")\n",
    "\n",
    "stopwords = StopWordsRemover().getStopWords()+ [\"-\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\")\n",
    "indexer = StringIndexer().setInputCol(\"spam\").setOutputCol(\"label\")\n",
    "lr = LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "pipeline = Pipeline().setStages([tokenizer, remover, cvmodel, indexer, lr])\n",
    "model = pipeline.fit(raw)\n",
    "model.write().overwrite().save(\"use_cases/spam_model4.4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
