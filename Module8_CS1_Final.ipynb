{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Module 8 Case Study 1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smsDF = spark.read.csv(\"/user/edureka_524533/Datasets/SMSSpamCollection\",inferSchema=True,header=False,sep='\\t').withColumnRenamed(\"_c0\",\"message_type\").withColumnRenamed(\"_c1\",\"message_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_type: string (nullable = true)\n",
      " |-- message_content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|message_type|     message_content|\n",
      "+------------+--------------------+\n",
      "|         ham|Go until jurong p...|\n",
      "|         ham|Ok lar... Joking ...|\n",
      "|        spam|Free entry in 2 a...|\n",
      "|         ham|U dun say so earl...|\n",
      "|         ham|Nah I don't think...|\n",
      "+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_messType(messType):\n",
    "    if messType == 'ham':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_convertToNumeric = udf(numeric_messType,IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace all 'ham' with 1 and 'spam' with 0, so we have numeric fields instead of string\n",
    "smsDFStat = smsDF.select('*',udf_convertToNumeric(smsDF['message_type']).alias('message_status'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+\n",
      "|message_type|     message_content|message_status|\n",
      "+------------+--------------------+--------------+\n",
      "|         ham|Go until jurong p...|             1|\n",
      "|         ham|Ok lar... Joking ...|             1|\n",
      "|        spam|Free entry in 2 a...|             0|\n",
      "|         ham|U dun say so earl...|             1|\n",
      "|         ham|Nah I don't think...|             1|\n",
      "+------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDFStat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_type: string (nullable = true)\n",
      " |-- message_content: string (nullable = true)\n",
      " |-- message_status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDFStat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(message):\n",
    "    messageEdit = [char for char in message if char not in string.punctuation]\n",
    "    message = ''.join(messageEdit)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_puncEdit = udf(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smsDF1 = (smsDFStat.select('*', udf_puncEdit(smsDFStat['message_content']).alias('message_punc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+--------------------+\n",
      "|message_type|     message_content|message_status|        message_punc|\n",
      "+------------+--------------------+--------------+--------------------+\n",
      "|         ham|Go until jurong p...|             1|Go until jurong p...|\n",
      "|         ham|Ok lar... Joking ...|             1|Ok lar Joking wif...|\n",
      "|        spam|Free entry in 2 a...|             0|Free entry in 2 a...|\n",
      "|         ham|U dun say so earl...|             1|U dun say so earl...|\n",
      "|         ham|Nah I don't think...|             1|Nah I dont think ...|\n",
      "+------------+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDF1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = StopWordsRemover.loadDefaultStopWords('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopWords(message):\n",
    "    wordList = message.split(' ')\n",
    "    messageEdit = [word for word in wordList if word not in stopWords]\n",
    "    message = ' '.join(messageEdit)\n",
    "    return message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_stopWEdit = udf(remove_stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smsDF2 = (smsDF1.select('*', udf_stopWEdit(smsDF1['message_punc']).alias('message_stopW')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+--------------------+--------------------+\n",
      "|message_type|     message_content|message_status|        message_punc|       message_stopW|\n",
      "+------------+--------------------+--------------+--------------------+--------------------+\n",
      "|         ham|Go until jurong p...|             1|Go until jurong p...|Go jurong point c...|\n",
      "|         ham|Ok lar... Joking ...|             1|Ok lar Joking wif...|Ok lar Joking wif...|\n",
      "|        spam|Free entry in 2 a...|             0|Free entry in 2 a...|Free entry 2 wkly...|\n",
      "|         ham|U dun say so earl...|             1|U dun say so earl...|U dun say early h...|\n",
      "|         ham|Nah I don't think...|             1|Nah I dont think ...|Nah I dont think ...|\n",
      "+------------+--------------------+--------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDF2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_type: string (nullable = true)\n",
      " |-- message_content: string (nullable = true)\n",
      " |-- message_status: integer (nullable = true)\n",
      " |-- message_punc: string (nullable = true)\n",
      " |-- message_stopW: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smsDF2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the number of columns in the dataset to message_status and message_stopW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = smsDF2.select('message_status','message_stopW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_status: integer (nullable = true)\n",
      " |-- message_stopW: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Message_Array\", split(col(\"message_stopW\"),\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+\n",
      "|message_status|       message_stopW|       Message_Array|\n",
      "+--------------+--------------------+--------------------+\n",
      "|             1|Go jurong point c...|[Go, jurong, poin...|\n",
      "|             1|Ok lar Joking wif...|[Ok, lar, Joking,...|\n",
      "|             0|Free entry 2 wkly...|[Free, entry, 2, ...|\n",
      "|             1|U dun say early h...|[U, dun, say, ear...|\n",
      "|             1|Nah I dont think ...|[Nah, I, dont, th...|\n",
      "|             0|FreeMsg Hey darli...|[FreeMsg, Hey, da...|\n",
      "|             1|Even brother like...|[Even, brother, l...|\n",
      "|             1|As per request Me...|[As, per, request...|\n",
      "|             0|WINNER As valued ...|[WINNER, As, valu...|\n",
      "|             0|Had mobile 11 mon...|[Had, mobile, 11,...|\n",
      "|             1|Im gonna home soo...|[Im, gonna, home,...|\n",
      "|             0|SIX chances win C...|[SIX, chances, wi...|\n",
      "|             0|URGENT You 1 week...|[URGENT, You, 1, ...|\n",
      "|             1|Ive searching rig...|[Ive, searching, ...|\n",
      "|             1|I HAVE A DATE ON ...|[I, HAVE, A, DATE...|\n",
      "|             0|XXXMobileMovieClu...|[XXXMobileMovieCl...|\n",
      "|             1|     Oh kim watching| [Oh, kim, watching]|\n",
      "|             1|Eh u remember 2 s...|[Eh, u, remember,...|\n",
      "|             1|Fine thats way u...|[Fine, thats, wa...|\n",
      "|             0|England v Macedon...|[England, v, Mace...|\n",
      "+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_status: integer (nullable = true)\n",
      " |-- message_stopW: string (nullable = true)\n",
      " |-- Message_Array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.select('message_status','Message_Array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_status: integer (nullable = true)\n",
      " |-- Message_Array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|message_status|       Message_Array|\n",
      "+--------------+--------------------+\n",
      "|             1|[Go, jurong, poin...|\n",
      "|             1|[Ok, lar, Joking,...|\n",
      "|             0|[Free, entry, 2, ...|\n",
      "|             1|[U, dun, say, ear...|\n",
      "|             1|[Nah, I, dont, th...|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sms_data = df1.select('Message_Array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#status_data = df1.select('message_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the whole dataframe into train and test DF\n",
    "trainData,testData = df1.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer,IDF,StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create CountVectorizer on the column which needs to be vectorized which is 'Message_Array'\n",
    "cv = CountVectorizer(inputCol=\"Message_Array\", outputCol=\"cv\", vocabSize=4, minDF=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"message_status\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[cv, idf, label_stringIdx, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipelineFit.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|message_status|       Message_Array|                 cv|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------+--------------------+-------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|             0|[08714712388, 10a...|          (4,[],[])|           (4,[],[])|  1.0|[1.72320551645813...|[0.84854126650309...|       0.0|\n",
      "|             0|[123, Congratulat...|(4,[0,2],[1.0,1.0])|(4,[0,2],[1.69448...|  1.0|[2.30787005352106...|[0.90952673939586...|       0.0|\n",
      "|             0|[18, days, Euro20...|          (4,[],[])|           (4,[],[])|  1.0|[1.72320551645813...|[0.84854126650309...|       0.0|\n",
      "|             0|[1st, wk, FREE, G...|(4,[2,3],[1.0,1.0])|(4,[2,3],[2.33296...|  1.0|[1.17969670190232...|[0.76489326557647...|       0.0|\n",
      "|             0|     [22, 146tf150p]|          (4,[],[])|           (4,[],[])|  1.0|[1.72320551645813...|[0.84854126650309...|       0.0|\n",
      "+--------------+--------------------+-------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|message_status|prediction|\n",
      "+--------------+----------+\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       1.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       1.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       1.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "|             0|       0.0|\n",
      "+--------------+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('message_status','prediction').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate1 = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='message_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc = evaluate1.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872277810476751"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48325363246162417"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"message_status\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[cv, idf, label_stringIdx, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pipelineFit.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"message_status\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"message_status\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ngrams(inputCol=\"Message_Array\", n=3):\n",
    "\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"Message_Array\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    vectorizers = [\n",
    "        CountVectorizer(inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_counts\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_counts\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "\n",
    "    return Pipeline(stages=ngrams + vectorizers + assembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline = build_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = build_ngrams().fit(trainData).transform(testData) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|message_status|       Message_Array|             1_grams|             2_grams|             3_grams|            1_counts|            2_counts|            3_counts|            features|\n",
      "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             0|[08714712388, 10a...|[08714712388, 10a...|[08714712388 10am...|[08714712388 10am...|(9441,[649,826,86...|(28685,[1341,1507...|(29594,[28827],[1...|(67720,[649,826,8...|\n",
      "|             0|[123, Congratulat...|[123, Congratulat...|[123 Congratulati...|[123 Congratulati...|(9441,[0,2,4,84,1...|(28685,[67,2372,2...|(29594,[1098,2200...|(67720,[0,2,4,84,...|\n",
      "|             0|[18, days, Euro20...|[18, days, Euro20...|[18 days, days Eu...|[18 days Euro2004...|(9441,[5,33,104,1...|(28685,[1944,2246...|(29594,[1969,2873...|(67720,[5,33,104,...|\n",
      "|             0|[1st, wk, FREE, G...|[1st, wk, FREE, G...|[1st wk, wk FREE,...|[1st wk FREE, wk ...|(9441,[2,3,66,90,...|(28685,[310,3212,...|       (29594,[],[])|(67720,[2,3,66,90...|\n",
      "|             0|     [22, 146tf150p]|     [22, 146tf150p]|      [22 146tf150p]|                  []| (9441,[8081],[1.0])|       (28685,[],[])|       (29594,[],[])|(67720,[8081],[1.0])|\n",
      "+--------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
