{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan the Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = '/mnt/home/edureka_524533/EronEmails/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_columns = ['ID','Date','From','To','Subject','MimeVer','ContentType','ContentEncoding','FromName','ToName','CC','BCC','Folder','Origin','FileName','Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = 'Emails.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from email.parser import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Def a function to perform all the above steps in one go\n",
    "def read_email_data(inpFile):\n",
    "    bodyList=[]\n",
    "    with open(inpFile,\"r\") as f:\n",
    "        data = ''\n",
    "        data = f.read()\n",
    "        email = Parser().parsestr(data)\n",
    "        messageIDList = email['Message-ID']\n",
    "        dateList = email['Date']\n",
    "        fromList = email['From']\n",
    "        \n",
    "        #toList.append(email['To'])\n",
    "        ###\n",
    "        if email['To']:\n",
    "            toEmail = email['To']\n",
    "            toEmail = toEmail.replace(\"\\n\", \"\")\n",
    "            toEmail = toEmail.replace(\"\\r\", \"\")\n",
    "            toEmail = toEmail.replace(\"\\t\", \"\")\n",
    "            toEmail = toEmail.replace(\" \", \"\")\n",
    "            toEmail = toEmail.split(\",\")\n",
    "            toList = ''.join(toEmail)\n",
    "        else:\n",
    "            toList = ''\n",
    "        ###\n",
    "        if email['Subject']:\n",
    "            data = email['Subject']\n",
    "            data = data.replace(\"\\n\",\"\")\n",
    "            data = data.replace(\"\\r\",\"\")\n",
    "            data = data.replace(\"\\t\",\"\")\n",
    "            subjectList = data\n",
    "        else:\n",
    "            subjectList = ''\n",
    "        #subjectList = email['Subject']\n",
    "        mimeVer = email['Mime-Version']\n",
    "        conTypeList = email['Content-Type']\n",
    "        conEncodList = email['Content-Transfer-Encoding']\n",
    "        fromNameList = email['X-From']\n",
    "        toNameList = email['X-To']\n",
    "        ccList = email['X-cc']\n",
    "        bccList = email['X-bcc']\n",
    "        folderList = email['X-Folder']\n",
    "        originList = email['X-Origin']\n",
    "        filenameList = email['X-FileName']\n",
    "        #bodyList = email.get_payload()\n",
    "        bodyList.append(email.get_payload())\n",
    "        ### Create a dictionary with key:email['item'] & value the corresponding data in it\n",
    "        dataDic = {}\n",
    "        dataDic['ID'] = messageIDList\n",
    "        dataDic['Date'] = dateList\n",
    "        dataDic['From'] = fromList\n",
    "        dataDic['To']=toList\n",
    "        dataDic['Subject']=subjectList \n",
    "        dataDic['MimeVer']=mimeVer\n",
    "        dataDic['ContentType']=conTypeList\n",
    "        dataDic['ContentEncoding']=conEncodList\n",
    "        dataDic['FromName']=fromNameList\n",
    "        dataDic['ToName']=toNameList\n",
    "        dataDic['CC']=ccList\n",
    "        dataDic['BCC']=bccList\n",
    "        dataDic['Folder']=folderList\n",
    "        dataDic['Origin']=originList\n",
    "        dataDic['FileName']=filenameList\n",
    "        dataDic['Body']=bodyList[:]\n",
    "        return dataDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open the csv file in append mode and write the header\n",
    "with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "#Call the os.walk to scan through folder tree structure and reach each file to populate the lists\n",
    "        for directory,subdirectory,filenames in os.walk(rootdir):\n",
    "        #initialize_process()\n",
    "            for filename in filenames:\n",
    "            #print(os.path.join(directory, filename))\n",
    "                dataDic = read_email_data(os.path.join(directory, filename))\n",
    "                writer.writerow(dataDic)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load csv to HDFS using:\n",
    "    # hdfs dfs -copyFromLocal 'EnronEmails.csv' 'Datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Module 8 Case Study 2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = spark.read.csv(\"/user/edureka_524533/Datasets/Emails.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- From: string (nullable = true)\n",
      " |-- To: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- MimeVer: string (nullable = true)\n",
      " |-- ContentType: string (nullable = true)\n",
      " |-- ContentEncoding: string (nullable = true)\n",
      " |-- FromName: string (nullable = true)\n",
      " |-- ToName: string (nullable = true)\n",
      " |-- CC: string (nullable = true)\n",
      " |-- BCC: string (nullable = true)\n",
      " |-- Folder: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- FileName: string (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#emailPD.head()\n",
    "emailDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the top 10 high-frequency users based on weekly numbers of emails sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpBySenderDF = emailDF.groupby('From').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10EmailSenders = gpBySenderDF.orderBy(col('count').desc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-----+\n",
      "|From                            |count|\n",
      "+--------------------------------+-----+\n",
      "|lynn.blair@enron.com            |1112 |\n",
      "|outlook.team@enron.com          |1030 |\n",
      "|no.address@enron.com            |106  |\n",
      "|john.buchanan@enron.com         |73   |\n",
      "|ava.garcia@enron.com            |52   |\n",
      "|michael.bodnar@enron.com        |38   |\n",
      "|special@flowgo.com              |38   |\n",
      "|newsletter@quickinspirations.com|37   |\n",
      "|updates@send4fun.com            |32   |\n",
      "|shelley.corman@enron.com        |27   |\n",
      "+--------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10EmailSenders.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract top 20 keywords from the subject text for both for the top 10 high-frequency users and for the non - high frequency users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a DF containing subject line along with Sender\n",
    "subjDF = emailDF.select('From','Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_rows_df = subjDF.filter(subjDF['From'].isNull()|subjDF['Subject'].isNull()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|                From|Subject|\n",
      "+--------------------+-------+\n",
      "|                null|   null|\n",
      "|courtney.barker@e...|   null|\n",
      "|michael.bodnar@en...|   null|\n",
      "|karen.clapper@enr...|   null|\n",
      "|  sales@webdesin.com|   null|\n",
      "|sharon.brown@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "|outlook.team@enro...|   null|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_rows_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10UsersDF = subjDF.groupby('From').count().orderBy(col('count').desc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                From|count|\n",
      "+--------------------+-----+\n",
      "|lynn.blair@enron.com| 1112|\n",
      "|outlook.team@enro...| 1030|\n",
      "|no.address@enron.com|  106|\n",
      "|john.buchanan@enr...|   73|\n",
      "|ava.garcia@enron.com|   52|\n",
      "|michael.bodnar@en...|   38|\n",
      "|  special@flowgo.com|   38|\n",
      "|newsletter@quicki...|   37|\n",
      "|updates@send4fun.com|   32|\n",
      "|shelley.corman@en...|   27|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10UsersDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10NonHighUsersDF = subjDF.groupby('From').count().orderBy(col('count').asc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                From|count|\n",
      "+--------------------+-----+\n",
      "|press.release@enr...|    1|\n",
      "|newsletter@rigzon...|    1|\n",
      "|elizabeth.bouldin...|    1|\n",
      "|  sales@webdesin.com|    1|\n",
      "|bob.d.johnson@mai...|    1|\n",
      "|dhenderson1@pclie...|    1|\n",
      "|thedesk@scudderpu...|    1|\n",
      "|announcements.enr...|    1|\n",
      "|ken.powers@enron.com|    1|\n",
      "|patrick.brennan@e...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10NonHighUsersDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Subject line for each of the ten users \n",
    "subjTopDF = top10UsersDF.join(subjDF,on=['From'],how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2545"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjTopDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- From: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      " |-- Subject: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjTopDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subNonHighTopDF = top10NonHighUsersDF.join(subjDF,on=['From'],how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- From: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      " |-- Subject: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subNonHighTopDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                From|count|             Subject|\n",
      "+--------------------+-----+--------------------+\n",
      "|shari.stack@enron...|    1|Confirmation Temp...|\n",
      "|lorna.pennicooke@...|    1|Testing the Servi...|\n",
      "|phil.lowry@enron.com|    1|    RE: OneOk Letter|\n",
      "|  sales@webdesin.com|    1|                null|\n",
      "|ld.stephens@enron...|    1|RE: Mt. Jesus Dri...|\n",
      "|bob.d.johnson@mai...|    1|          Borderline|\n",
      "|kkeuter@ftenergy.com|    1|Northern Natural Gas|\n",
      "|james.saunders@en...|    1|RE: TW/ENA compre...|\n",
      "|frankie.adams@enr...|    1|RE: Hartley IA TB...|\n",
      "|tom.halpin@enron.com|    1|Follow up on the ...|\n",
      "+--------------------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subNonHighTopDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,explode,split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|     Enron|    2|\n",
      "|       and|    2|\n",
      "|       RE:|    2|\n",
      "|       Mt.|    1|\n",
      "|     Jesus|    1|\n",
      "|      Drip|    1|\n",
      "|     Oneok|    1|\n",
      "|       FW:|    1|\n",
      "|   2001-20|    1|\n",
      "|          |    1|\n",
      "|   Hartley|    1|\n",
      "|   payment|    1|\n",
      "|    Follow|    1|\n",
      "|Borderline|    1|\n",
      "|  Northern|    1|\n",
      "|   Natural|    1|\n",
      "|       Gas|    1|\n",
      "|        IA|    1|\n",
      "|       TBS|    1|\n",
      "|        #1|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDF = subNonHighTopDF.withColumn('word', explode(split(col('Subject'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .limit(20)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now to extract the Top 20 keywords in for Top 10 Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|       FW:|  454|\n",
      "|         -|  454|\n",
      "|       RE:|  397|\n",
      "|      Mtg.|  283|\n",
      "|      room|  273|\n",
      "|Conference|  220|\n",
      "|   Meeting|  178|\n",
      "|    EB4102|  168|\n",
      "|       for|  164|\n",
      "|    Oncall|  119|\n",
      "|     Staff|  112|\n",
      "|          |  106|\n",
      "|    Weekly|  103|\n",
      "|        in|   97|\n",
      "|        to|   96|\n",
      "|       Re:|   89|\n",
      "|      Team|   85|\n",
      "|        TW|   83|\n",
      "|        on|   82|\n",
      "|conference|   80|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDF = subjTopDF.withColumn('word', explode(split(col('Subject'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .limit(20)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract top 10 keywords by identifying removing the common stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- From: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = StopWordsRemover.loadDefaultStopWords('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopWords(message):\n",
    "    if message is None:\n",
    "        return ' '\n",
    "    else:\n",
    "        wordList = message.split(' ')\n",
    "        messageEdit = [word for word in wordList if word not in stopWords]\n",
    "        message = ' '.join(messageEdit)\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_stopWEdit = udf(remove_stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjCleanDF = (subjDF.select('*', udf_stopWEdit(subjDF['Subject']).alias('Subject_stopW')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- From: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- Subject_stopW: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjCleanDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                From|             Subject|       Subject_stopW|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|amy.fitzpatrick@e...|Fitness Club Reim...|Fitness Club Reim...|\n",
      "|office.chairman@e...|Organisational An...|Organisational An...|\n",
      "|enron.announcemen...|2000 Chairman's A...|2000 Chairman's A...|\n",
      "|casey@mercatorpar...|         GOOD ADVICE|         GOOD ADVICE|\n",
      "|office.chairman@e...|      Code of Ethics|         Code Ethics|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjCleanDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|       RE:|  590|\n",
      "|       FW:|  567|\n",
      "|         -|  536|\n",
      "|      Mtg.|  284|\n",
      "|      room|  273|\n",
      "|          |  243|\n",
      "|Conference|  231|\n",
      "|   Meeting|  225|\n",
      "|    EB4102|  168|\n",
      "|    Oncall|  120|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDF = subjCleanDF.withColumn('word', explode(split(col('Subject_stopW'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .limit(10)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend the stop words dictionary by adding your own stop words such as ‘ —‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuations(message):\n",
    "    print(message)\n",
    "    if message is None:\n",
    "        return ' '\n",
    "    else: \n",
    "        messageEdit = [char for char in message if char not in string.punctuation]\n",
    "        message = ''.join(messageEdit)\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_puncEdit = udf(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjNoPuncDF = (subjCleanDF.select('*', udf_puncEdit(subjCleanDF['Subject_stopW']).alias('Subject_punc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                From|             Subject|       Subject_stopW|        Subject_punc|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|amy.fitzpatrick@e...|Fitness Club Reim...|Fitness Club Reim...|Fitness Club Reim...|\n",
      "|office.chairman@e...|Organisational An...|Organisational An...|Organisational An...|\n",
      "|enron.announcemen...|2000 Chairman's A...|2000 Chairman's A...|2000 Chairmans Award|\n",
      "|casey@mercatorpar...|         GOOD ADVICE|         GOOD ADVICE|         GOOD ADVICE|\n",
      "|office.chairman@e...|      Code of Ethics|         Code Ethics|         Code Ethics|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjNoPuncDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|          |  974|\n",
      "|        RE|  590|\n",
      "|        FW|  571|\n",
      "|       Mtg|  325|\n",
      "|      room|  273|\n",
      "|   Meeting|  236|\n",
      "|Conference|  232|\n",
      "|    EB4102|  169|\n",
      "|       Gas|  125|\n",
      "|    Oncall|  121|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordDF = subjNoPuncDF.withColumn('word', explode(split(col('Subject_punc'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .limit(10)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce a new column label to identify new, replied, and forwarded messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forwarded = 'fwd:'\n",
    "forward = 'fw:'\n",
    "replied = 're:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkMessageType(message):\n",
    "    if message is None:\n",
    "        return 'n'\n",
    "    message = message.lower()\n",
    "    messageList = message.split(' ')\n",
    "    if (forwarded in messageList) or (forward in messageList):\n",
    "        return 'f'\n",
    "    elif replied in messageList:\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_emailType = udf(checkMessageType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = (emailDF.select('*', udf_emailType(emailDF['Subject']).alias('Email_Type')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNewEmail(emailType):\n",
    "    if emailType == 'n':#if new set indicator to 'Y\n",
    "        result = 'Y'\n",
    "    else:\n",
    "        result = 'N'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkForwardedEmail(emailType):\n",
    "    if emailType == 'f':\n",
    "        result = 'Y'\n",
    "    else:\n",
    "        result = 'N'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkRepliedEmail(emailType):\n",
    "    if emailType == 'r':\n",
    "        result = 'Y'\n",
    "    else:\n",
    "        result = 'N'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_newEmail = udf(checkNewEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_forwardedEmail = udf(checkForwardedEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udf_repliedEmail = udf(checkRepliedEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = (emailDF.select('*', udf_newEmail(emailDF['Email_Type']).alias('NewEmail')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = (emailDF.select('*', udf_forwardedEmail(emailDF['Email_Type']).alias('ForwardedEmail')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = (emailDF.select('*', udf_repliedEmail(emailDF['Email_Type']).alias('RepliedEmail')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the trend of the over mail activity using the pivot table from spark itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- From: string (nullable = true)\n",
      " |-- To: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- MimeVer: string (nullable = true)\n",
      " |-- ContentType: string (nullable = true)\n",
      " |-- ContentEncoding: string (nullable = true)\n",
      " |-- FromName: string (nullable = true)\n",
      " |-- ToName: string (nullable = true)\n",
      " |-- CC: string (nullable = true)\n",
      " |-- BCC: string (nullable = true)\n",
      " |-- Folder: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- FileName: string (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Email_Type: string (nullable = true)\n",
      " |-- NewEmail: string (nullable = true)\n",
      " |-- ForwardedEmail: string (nullable = true)\n",
      " |-- RepliedEmail: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-----------------------------+\n",
      "|Date                                 |From                         |\n",
      "+-------------------------------------+-----------------------------+\n",
      "|Tue, 22 Aug 2000 01:06:00 -0700 (PDT)|amy.fitzpatrick@enron.com    |\n",
      "|Mon, 31 Jul 2000 11:07:00 -0700 (PDT)|office.chairman@enron.com    |\n",
      "|Fri, 11 Aug 2000 18:20:00 -0700 (PDT)|enron.announcements@enron.com|\n",
      "|Wed, 7 Jun 2000 16:17:00 -0700 (PDT) |casey@mercatorpartners.com   |\n",
      "|Mon, 14 Aug 2000 13:19:00 -0700 (PDT)|office.chairman@enron.com    |\n",
      "|Mon, 10 Jul 2000 10:50:00 -0700 (PDT)|enron.chairman@enron.com     |\n",
      "|Wed, 9 Aug 2000 13:28:00 -0700 (PDT) |office.chairman@enron.com    |\n",
      "|Sun, 21 May 2000 18:55:00 -0700 (PDT)|office.chairman@enron.com    |\n",
      "|Wed, 17 May 2000 04:13:00 -0700 (PDT)|office.chairman@enron.com    |\n",
      "|Wed, 23 Aug 2000 09:16:00 -0700 (PDT)|office.chairman@enron.com    |\n",
      "|Mon, 24 Jan 2000 02:06:00 -0800 (PST)|office.chairman@enron.com    |\n",
      "|Tue, 25 Jul 2000 08:14:00 -0700 (PDT)|christian.yoder@enron.com    |\n",
      "|Thu, 17 Aug 2000 11:28:00 -0700 (PDT)|dlevine@caiso.com            |\n",
      "|Fri, 28 Jul 2000 02:20:00 -0700 (PDT)|drew_a_brabb@calpx.com       |\n",
      "|Fri, 25 Aug 2000 03:51:00 -0700 (PDT)|enron.announcements@enron.com|\n",
      "|Tue, 29 Aug 2000 03:10:00 -0700 (PDT)|cgrant@caiso.com             |\n",
      "|Mon, 10 Jul 2000 10:50:00 -0700 (PDT)|enron.chairman@enron.com     |\n",
      "|Fri, 4 Aug 2000 03:48:00 -0700 (PDT) |foothi19@idt.net             |\n",
      "|Thu, 27 Jul 2000 01:06:00 -0700 (PDT)|robert.badeer@enron.com      |\n",
      "|Wed, 16 Aug 2000 06:19:00 -0700 (PDT)|crcommunications@caiso.com   |\n",
      "+-------------------------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF['Date','From'].show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badDF = emailDF.filter(emailDF['Date'].isNull()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fri, 4 Aug 2000 03:48:00 -0700 (PDT)\n",
    "# Extract Day, Date, Month, Year   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_pattern='\\w{3},'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = emailDF.withColumn('Day', regexp_extract(col('Date'), day_pattern, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+----+\n",
      "|                Date| Day|Month|Year|\n",
      "+--------------------+----+-----+----+\n",
      "|Tue, 22 Aug 2000 ...|Tue,| Aug |2000|\n",
      "|Mon, 31 Jul 2000 ...|Mon,| Jul |2000|\n",
      "|Fri, 11 Aug 2000 ...|Fri,| Aug |2000|\n",
      "|Wed, 7 Jun 2000 1...|Wed,| Jun |2000|\n",
      "|Mon, 14 Aug 2000 ...|Mon,| Aug |2000|\n",
      "|Mon, 10 Jul 2000 ...|Mon,| Jul |2000|\n",
      "|Wed, 9 Aug 2000 1...|Wed,| Aug |2000|\n",
      "|Sun, 21 May 2000 ...|Sun,| May |2000|\n",
      "|Wed, 17 May 2000 ...|Wed,| May |2000|\n",
      "|Wed, 23 Aug 2000 ...|Wed,| Aug |2000|\n",
      "|Mon, 24 Jan 2000 ...|Mon,| Jan |2000|\n",
      "|Tue, 25 Jul 2000 ...|Tue,| Jul |2000|\n",
      "|Thu, 17 Aug 2000 ...|Thu,| Aug |2000|\n",
      "|Fri, 28 Jul 2000 ...|Fri,| Jul |2000|\n",
      "|Fri, 25 Aug 2000 ...|Fri,| Aug |2000|\n",
      "|Tue, 29 Aug 2000 ...|Tue,| Aug |2000|\n",
      "|Mon, 10 Jul 2000 ...|Mon,| Jul |2000|\n",
      "|Fri, 4 Aug 2000 0...|Fri,| Aug |2000|\n",
      "|Thu, 27 Jul 2000 ...|Thu,| Jul |2000|\n",
      "|Wed, 16 Aug 2000 ...|Wed,| Aug |2000|\n",
      "+--------------------+----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF['Date','Day','Month','Year'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_pattern=' \\w{3} '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = emailDF.withColumn('Month', regexp_extract(col('Date'), month_pattern, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_pattern = '[1-2]\\d{3}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emailDF = emailDF.withColumn('Year', regexp_extract(col('Date'), year_pattern, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- From: string (nullable = true)\n",
      " |-- To: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- MimeVer: string (nullable = true)\n",
      " |-- ContentType: string (nullable = true)\n",
      " |-- ContentEncoding: string (nullable = true)\n",
      " |-- FromName: string (nullable = true)\n",
      " |-- ToName: string (nullable = true)\n",
      " |-- CC: string (nullable = true)\n",
      " |-- BCC: string (nullable = true)\n",
      " |-- Folder: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- FileName: string (nullable = true)\n",
      " |-- Body: string (nullable = true)\n",
      " |-- Email_Type: string (nullable = true)\n",
      " |-- NewEmail: string (nullable = true)\n",
      " |-- ForwardedEmail: string (nullable = true)\n",
      " |-- RepliedEmail: string (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+----+\n",
      "|                From|   f|   n|   r|\n",
      "+--------------------+----+----+----+\n",
      "|alice.johnson@enr...|   1|   3|null|\n",
      "| rick.kile@enron.com|   1|null|   1|\n",
      "|announcements.enr...|null|   1|null|\n",
      "|thedesk@scudderpu...|null|   1|null|\n",
      "|dhenderson1@pclie...|null|   1|null|\n",
      "|integrated.soluti...|null|   3|null|\n",
      "|nancy.bagot@enron...|null|   3|null|\n",
      "|   40enron@enron.com|null|   8|   1|\n",
      "|ken.powers@enron.com|null|   1|null|\n",
      "|maggie.matheson@e...|null|   4|null|\n",
      "|    ipayit@enron.com|null|   2|null|\n",
      "|  sales@webdesin.com|null|   1|null|\n",
      "|michele.winckowsk...|null|   4|   7|\n",
      "|elizabeth.bouldin...|null|   1|null|\n",
      "|bob.d.johnson@mai...|null|   1|null|\n",
      "|raetta.zadow@enro...|  10|  11|   6|\n",
      "|e..anderson@enron...|   2|   1|   5|\n",
      "|press.release@enr...|null|   1|null|\n",
      "|newsletter@rigzon...|null|   1|null|\n",
      "|   news@real-net.net|null|   3|null|\n",
      "+--------------------+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF.groupBy('From').pivot('Email_Type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+-------+-------+-----------+---------------+--------+------+----+----+------+------+--------+--------------------+----------+--------+--------------+------------+----+-----+----+\n",
      "|  ID|Date|From|  To|Subject|MimeVer|ContentType|ContentEncoding|FromName|ToName|  CC| BCC|Folder|Origin|FileName|                Body|Email_Type|NewEmail|ForwardedEmail|RepliedEmail| Day|Month|Year|\n",
      "+----+----+----+----+-------+-------+-----------+---------------+--------+------+----+----+------+------+--------+--------------------+----------+--------+--------------+------------+----+-----+----+\n",
      "|null|null|null|null|   null|   null|       null|           null|    null|  null|null|null|  null|  null|    null|['\\x00\\x00\\x00\\x0...|         n|       Y|             N|           N|null| null|null|\n",
      "+----+----+----+----+-------+-------+-----------+---------------+--------+------+----+----+------+------+--------+--------------------+----------+--------+--------------+------------+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "badDF = emailDF.filter(emailDF['Year'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+----+\n",
      "|                From|   f|   n|   r|\n",
      "+--------------------+----+----+----+\n",
      "|alice.johnson@enr...|   1|   3|null|\n",
      "|thedesk@scudderpu...|null|   1|null|\n",
      "| rick.kile@enron.com|   1|null|   1|\n",
      "|announcements.enr...|null|   1|null|\n",
      "|integrated.soluti...|null|   3|null|\n",
      "|dhenderson1@pclie...|null|   1|null|\n",
      "|nancy.bagot@enron...|null|   3|null|\n",
      "|   40enron@enron.com|null|   8|   1|\n",
      "|maggie.matheson@e...|null|   4|null|\n",
      "|ken.powers@enron.com|null|   1|null|\n",
      "|    ipayit@enron.com|null|   2|null|\n",
      "|  sales@webdesin.com|null|   1|null|\n",
      "|elizabeth.bouldin...|null|   1|null|\n",
      "|michele.winckowsk...|null|   4|   7|\n",
      "|raetta.zadow@enro...|  10|  11|   6|\n",
      "|bob.d.johnson@mai...|null|   1|null|\n",
      "|e..anderson@enron...|   2|   1|   5|\n",
      "|press.release@enr...|null|   1|null|\n",
      "|newsletter@rigzon...|null|   1|null|\n",
      "|   news@real-net.net|null|   3|null|\n",
      "+--------------------+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emailDF.filter(emailDF['Year'].isNotNull()).groupBy('From').pivot('Email_Type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use k-means clustering to create 4 clusters from the extracted keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans,KMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all words from subject line and order them in descending order\n",
    "allWordsDF = subjNoPuncDF.withColumn('word', explode(split(col('Subject_punc'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllWordsDF= spark.createDataFrame(allWordsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AllWordsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Requirement is to create 4 clusters so K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = VectorAssembler(inputCols=['count'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newVecDF = vc.transform(AllWordsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+\n",
      "|word|count|features|\n",
      "+----+-----+--------+\n",
      "|    |  974| [974.0]|\n",
      "|  RE|  590| [590.0]|\n",
      "|  FW|  571| [571.0]|\n",
      "| Mtg|  325| [325.0]|\n",
      "|room|  273| [273.0]|\n",
      "+----+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newVecDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=4,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kmeans.fit(newVecDF.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.transform(newVecDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+----------+\n",
      "|word|count|features|prediction|\n",
      "+----+-----+--------+----------+\n",
      "|    |  974| [974.0]|         1|\n",
      "|  RE|  590| [590.0]|         3|\n",
      "|  FW|  571| [571.0]|         3|\n",
      "| Mtg|  325| [325.0]|         3|\n",
      "|room|  273| [273.0]|         3|\n",
      "+----+-----+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.22195775]\n",
      "[974.]\n",
      "[67.34883721]\n",
      "[371.16666667]\n"
     ]
    }
   ],
   "source": [
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LDA to generate 4 topics from the extracted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a LDA model.\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model1 = lda.fit(newVecDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------+-----------+\n",
      "|topic|termIndices|termWeights|\n",
      "+-----+-----------+-----------+\n",
      "|0    |[0]        |[1.0]      |\n",
      "|1    |[0]        |[1.0]      |\n",
      "|2    |[0]        |[1.0]      |\n",
      "|3    |[0]        |[1.0]      |\n",
      "|4    |[0]        |[1.0]      |\n",
      "|5    |[0]        |[1.0]      |\n",
      "|6    |[0]        |[1.0]      |\n",
      "|7    |[0]        |[1.0]      |\n",
      "|8    |[0]        |[1.0]      |\n",
      "|9    |[0]        |[1.0]      |\n",
      "+-----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|word      |count|features|topicDistribution                                                                                                                                                                                                         |\n",
      "+----------+-----+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|          |974  |[974.0] |[1.0114433398680371E-4,1.0078016005676634E-4,1.0081246419437194E-4,1.0115524146413965E-4,1.0063162334282231E-4,1.0140054313467611E-4,1.0074216062689085E-4,1.0052439231682387E-4,1.005975471431424E-4,0.9990922115337335] |\n",
      "|RE        |590  |[590.0] |[1.668643364495297E-4,1.662635348231376E-4,1.663145840494268E-4,1.6688233123074775E-4,1.6601848406411847E-4,1.6728702149888523E-4,1.6620084467121448E-4,1.6584185924967823E-4,0.998501512650346,1.6681435361716985E-4]    |\n",
      "|FW        |571  |[571.0] |[1.7240719488028895E-4,0.9984520368305188,1.7183918090431523E-4,1.724257874089164E-4,1.7153324512366984E-4,1.7285492349736076E-4,1.717216633521327E-4,1.7135046263552835E-4,1.7147515995176736E-4,1.7235555172719059E-4]  |\n",
      "|Mtg       |325  |[325.0] |[3.025125386336153E-4,3.014233288446393E-4,3.0151587738880574E-4,3.0254516186805264E-4,3.0098805664707594E-4,3.0327883601190275E-4,3.013096761472055E-4,3.0065835176238976E-4,3.0087715091465356E-4,0.9972848910217816]   |\n",
      "|room      |273  |[273.0] |[3.5992717628415363E-4,3.5863124180023634E-4,3.5874135543488594E-4,3.599911447084365E-4,3.5810266514415477E-4,3.608389117680548E-4,3.5849601858638507E-4,3.577210772257907E-4,3.579814029806149E-4,0.9967695690060673]    |\n",
      "|Meeting   |236  |[236.0] |[4.1612229675341E-4,4.1462473673463905E-4,4.1475133397951113E-4,4.161671718210437E-4,4.140129251361809E-4,4.171763812949966E-4,0.996263703013492,4.1357175999624774E-4,4.1387273034262E-4,4.15997650449298E-4]            |\n",
      "|Conference|232  |[232.0] |[4.232665390333677E-4,4.2174254731619184E-4,0.9961998450240434,4.2331218454683074E-4,4.211209522861899E-4,4.2433872081957993E-4,4.215835276603728E-4,4.2067240104447766E-4,4.2097835053308115E-4,4.2313975271633864E-4]   |\n",
      "|EB4102    |169  |[169.0] |[5.801395456725673E-4,5.780512895757818E-4,0.994791413681798,5.802021086366695E-4,5.771987470828566E-4,5.816091067905659E-4,5.778327652464445E-4,5.765836929352121E-4,5.770032933130273E-4,5.799657689489519E-4]          |\n",
      "|Gas       |125  |[125.0] |[7.827548065407828E-4,7.799364498446207E-4,7.801759214257081E-4,7.828392199565428E-4,7.78786918420313E-4,0.9929768633197081,7.796423707643883E-4,7.779570533908592E-4,7.785232013961377E-4,7.825207385523664E-4]          |\n",
      "|Oncall    |121  |[121.0] |[8.084224130662976E-4,8.055116377775191E-4,8.057608404114338E-4,8.085095945384456E-4,8.043244113180426E-4,8.104702461072129E-4,8.052079153578181E-4,0.9927395606395918,8.040520465774343E-4,8.081802552539052E-4]         |\n",
      "|Weekly    |117  |[117.0] |[0.9924985336122873,8.32820979247328E-4,8.330766886221572E-4,8.359205768424991E-4,8.315935018187207E-4,8.37947701119913E-4,8.325069596158994E-4,8.307073663337499E-4,8.31311902998155E-4,8.35580711114215E-4]             |\n",
      "|Staff     |117  |[117.0] |[8.358304453542094E-4,8.328209847583716E-4,8.330766941515137E-4,8.359205825790334E-4,8.315935072425732E-4,8.379477070081186E-4,8.325069651045249E-4,8.307642456971842E-4,0.9924939587905478,8.355800775567072E-4]         |\n",
      "|TW        |117  |[117.0] |[8.358304444603397E-4,8.328209838979503E-4,8.330766932882913E-4,8.359205816841455E-4,8.315935063954919E-4,8.37947706090074E-4,8.325526768037672E-4,8.307073708578303E-4,0.9924939699598564,8.35580076665661E-4]           |\n",
      "|Re        |102  |[102.0] |[9.575730610971253E-4,9.541252542898756E-4,9.544182093035415E-4,9.576763273582974E-4,9.527189872597995E-4,9.599987148533555E-4,9.537654957745424E-4,0.9913999902571872,9.524474671722191E-4,9.572862257041319E-4]         |\n",
      "|Team      |98   |[98.0]  |[9.96269411351856E-4,9.927714262480275E-4,9.929870679169933E-4,9.963768507369143E-4,9.912191781300973E-4,9.987930889424335E-4,9.923079773953329E-4,9.901629458095946E-4,0.9910531410689007,9.959709845679121E-4]          |\n",
      "|2001      |93   |[93.0]  |[0.0010492718709458916,0.001045493893084969,0.001045815715725329,0.0010493850262576856,0.0010439529582540704,0.0010519298117551425,0.9905787531752756,0.001042840532910772,0.0010435994483538789,0.001048957567436633]    |\n",
      "|TMS       |81   |[81.0]  |[0.001202855125386309,0.001198524153459044,0.0011988921496852445,0.0012029848435873897,0.0011967576673916598,0.0012059021171798518,0.0011980722418384303,0.001195482413048835,0.0011963544030594293,0.9892041748853638]   |\n",
      "|Customer  |81   |[81.0]  |[0.0012028551290954581,0.0011985241570212646,0.0011988921532597482,0.0012029848473010202,0.0011967576708954322,0.0012059021209955278,0.0011980722453856178,0.0011955119438934892,0.0011963524166864851,0.9892041473154659]|\n",
      "|Report    |81   |[81.0]  |[0.0012028551452255161,0.9892000301662576,0.0011988921688390272,0.0012029848634493756,0.0011967576861845785,0.0012059021375599491,0.0011980722608529145,0.0011954824316288894,0.001196528303914425,0.0012024948360876196] |\n",
      "|conference|80   |[80.0]  |[0.0012177082505145783,0.0012133237981152767,0.00121370528917439,0.0012178395705251936,0.0012115354988192027,0.9890743080569666,0.001212866306121103,0.0012102444971624725,0.0012111252403941312,0.0012173434922068654]   |\n",
      "+----------+-----+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the result\n",
    "transformed = model1.transform(newVecDF)\n",
    "transformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
